{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image analysis results:\n",
      " Objects:\n",
      "   'stop sign', {'x': 177, 'y': 74, 'w': 32, 'h': 31}, Confidence: 0.5680\n",
      "   'stop sign', {'x': 277, 'y': 72, 'w': 36, 'h': 39}, Confidence: 0.5860\n",
      "   'stop sign', {'x': 375, 'y': 67, 'w': 47, 'h': 44}, Confidence: 0.5430\n",
      "   'stop sign', {'x': 243, 'y': 101, 'w': 41, 'h': 36}, Confidence: 0.6460\n",
      "   'stop sign', {'x': 185, 'y': 119, 'w': 30, 'h': 27}, Confidence: 0.5250\n",
      "   'stop sign', {'x': 184, 'y': 150, 'w': 32, 'h': 32}, Confidence: 0.5190\n",
      "   'stop sign', {'x': 246, 'y': 138, 'w': 37, 'h': 36}, Confidence: 0.6510\n",
      "   'stop sign', {'x': 368, 'y': 17, 'w': 59, 'h': 79}, Confidence: 0.7020\n",
      "   'car', {'x': 0, 'y': 213, 'w': 220, 'h': 55}, Confidence: 0.8010\n",
      "[{'x': 177, 'y': 74, 'w': 32, 'h': 31}, {'x': 277, 'y': 72, 'w': 36, 'h': 39}, {'x': 375, 'y': 67, 'w': 47, 'h': 44}, {'x': 243, 'y': 101, 'w': 41, 'h': 36}, {'x': 185, 'y': 119, 'w': 30, 'h': 27}, {'x': 184, 'y': 150, 'w': 32, 'h': 32}, {'x': 246, 'y': 138, 'w': 37, 'h': 36}, {'x': 368, 'y': 17, 'w': 59, 'h': 79}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint = \"https://5a030comvision.cognitiveservices.azure.com/\"\n",
    "key = \"C8Egslzv6b8fTXJIlcl0JNgPDNkpqGPGbeBONTzCFAycNP7tDcSBJQQJ99ALACYeBjFXJ3w3AAAFACOG5kUk\"\n",
    "\n",
    "client = ImageAnalysisClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "# Load image to analyze into a 'bytes' object\n",
    "with open(\"Fullimage.jpg\", \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "visual_features =[ #Azure AI Vision 모든 기능 사용 가능\n",
    "        VisualFeatures.OBJECTS,\n",
    "        VisualFeatures.SMART_CROPS\n",
    "    ]\n",
    "\n",
    "# Analyze all visual features from an image stream. This will be a synchronously (blocking) call.\n",
    "result = client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=visual_features,\n",
    "    smart_crops_aspect_ratios=[0.9, 1.33],\n",
    "    gender_neutral_caption=True,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "# Print all analysis results to the console\n",
    "print(\"Image analysis results:\")\n",
    "\n",
    "stop_sign = []\n",
    "if result.objects is not None:\n",
    "    print(\" Objects:\")\n",
    "    for object in result.objects.list:\n",
    "        tag_name = object.tags[0].name\n",
    "        print(f\"   '{tag_name}', {object.bounding_box}, Confidence: {object.tags[0].confidence:.4f}\")\n",
    "        if tag_name == \"stop sign\":\n",
    "            stop_sign.append(object.bounding_box)\n",
    "\n",
    "print(stop_sign)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped image saved to: cropped_images\\stop_sign_1.jpg\n",
      "Cropped image saved to: cropped_images\\stop_sign_2.jpg\n",
      "Cropped image saved to: cropped_images\\stop_sign_3.jpg\n",
      "Cropped image saved to: cropped_images\\stop_sign_4.jpg\n",
      "Cropped image saved to: cropped_images\\stop_sign_5.jpg\n",
      "Cropped image saved to: cropped_images\\stop_sign_6.jpg\n",
      "Cropped image saved to: cropped_images\\stop_sign_7.jpg\n",
      "Cropped image saved to: cropped_images\\stop_sign_8.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 원본 이미지 경로\n",
    "original_image_path = \"Fullimage.jpg\"\n",
    "\n",
    "# bounding_boxes 변수에 stop_sign 리스트 할당\n",
    "bounding_boxes = [bbox for bbox in stop_sign]\n",
    "\n",
    "# 출력 디렉토리 설정\n",
    "output_directory = \"cropped_images\"\n",
    "\n",
    "# 출력 디렉토리가 존재하면 내용을 비우고, 존재하지 않으면 새로 생성\n",
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)\n",
    "os.makedirs(output_directory)\n",
    "\n",
    "# 원본 이미지 열기\n",
    "img = Image.open(original_image_path)\n",
    "\n",
    "# 각 bounding box에 대해 이미지 자르기 및 저장\n",
    "for i, bbox in enumerate(bounding_boxes):\n",
    "    cropped_img = img.crop((bbox['x'], bbox['y'], bbox['x'] + bbox['w'], bbox['y'] + bbox['h']))\n",
    "    \n",
    "    cropped_image_path = os.path.join(output_directory, f\"stop_sign_{i + 1}.jpg\")\n",
    "    cropped_img.save(cropped_image_path)\n",
    "    print(f\"Cropped image saved to: {cropped_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
